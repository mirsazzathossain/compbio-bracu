{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/mirsazzathossain/compbio-bracu/blob/main/day_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## **Day 03: Interdisciplinary Computational Biology workshop 2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Import Libraries**\n",
    "\n",
    "To get started, we need to import a set of essential libraries that will help us perform various tasks:\n",
    "\n",
    "- **`numpy`**: For efficient numerical computations.\n",
    "- **`pandas`**: To handle and manipulate structured data.\n",
    "- **`matplotlib` and `seaborn`**: For creating insightful visualizations.\n",
    "- **`sklearn`**: To build and evaluate machine learning models.\n",
    "\n",
    "Let's import them now!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Load Data**\n",
    "\n",
    "For this task, you are provided with data files containing information about different proteins. Each group is assigned a specific protein dataset, and they will focus on analyzing and processing their assigned file.\n",
    "\n",
    "Protein Files for Groups:\n",
    "\n",
    "- Group 1: `akt1.csv`\n",
    "- Group 2: `casp3.csv`\n",
    "- Group 3: `pa2ga.csv`\n",
    "- Group 4: `cxcr4.csv`\n",
    "- Group 5: `cp3a4.csv`\n",
    "\n",
    "Each group should load their assigned protein file into a pandas DataFrame for further analysis. Use the `pd.read_csv()` function to load the data, and display the first few rows of the DataFrame to understand the available columns and data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the data and print the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Explore the Dataset**\n",
    "\n",
    "To begin working with the dataset, it is essential to understand its structure and key statistics.\n",
    "\n",
    "**Tasks for Exploration**:\n",
    "\n",
    "1. Use `.info()` to check the dataset's structure, including the number of rows, columns, and data types\n",
    "2. Use `.describe()` to summarize the statistics of all numerical features.\n",
    "\n",
    "**Things to Observe**:\n",
    "\n",
    "- Are there any missing values in the dataset?\n",
    "- What are the ranges of the numerical features?\n",
    "- Are the data types appropriate for analysis?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the basic information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display some basic statistics of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 4: Visualizing Numerical Features**\n",
    "\n",
    "In this part, we will visualize the distribution and spread of numerical features using histograms and boxplots to better understand the statistics from the `describe()` function.\n",
    "\n",
    "#### **4.1 Histograms**:\n",
    "\n",
    "Histograms help visualize the distribution of numerical data. By adding a Kernel Density Estimate (KDE), we can see the shape and spread of the data.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Complete the code to loop through each numerical column.\n",
    "2. Plot a histogram with a KDE for each numerical feature.\n",
    "3. Observe the shape and spread of the distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the style to whitegrid\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure()\n",
    "\n",
    "# create a 6x4 grid of histograms\n",
    "fig, axes = plt.subplots(6, 4, figsize=(20, 20))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# iterate over each column and plot the histogram\n",
    "for i, column in enumerate(data.columns):\n",
    "    # plot only if the numeric column\n",
    "    if data[column].dtype != \"object\":\n",
    "        # TODO:\n",
    "        # use sns.histplot to plot the histogram\n",
    "        # set kde=True to plot the kernel density estimate\n",
    "        # set bins to the square root of the number of samples\n",
    "        # set ax=axes[i] to plot on the correct axis\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2 Boxplot**\n",
    "\n",
    "Boxplots provide a summary of the data's distribution by displaying the median, quartiles, and potential outliers. They help us visually assess the spread of values and highlight any extreme values.\n",
    "\n",
    "![boxplot](https://miro.medium.com/v2/resize:fit:700/0*XG2sFucPoFMg6NeV.png)\n",
    "\n",
    "**Instructions**:\n",
    "\n",
    "1. Complete the code to loop through each numerical column.\n",
    "2. Plot a boxplot for each numerical feature.\n",
    "3. Identify the median, IQR, and any outliers in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the style to whitegrid\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure()\n",
    "\n",
    "# create a 6x4 grid of histograms\n",
    "fig, axes = plt.subplots(6, 4, figsize=(20, 20))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# iterate over each column and plot the histogram\n",
    "for i, column in enumerate(data.columns):\n",
    "    # plot only if the numeric column\n",
    "    if data[column].dtype != \"object\":\n",
    "        # TODO:\n",
    "        # use sns.boxplot to plot the boxplot\n",
    "        # set ax=axes[i] to plot on the correct axis\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Data Preprocessing**\n",
    "\n",
    "#### **5.1 Data Cleaning**\n",
    "\n",
    "Based on the observations from the dataset, you might need to clean the data before building the machine learning model. Here are some important observations you might consider:\n",
    "\n",
    "1. **Convert Categorical Variables:** The `Name` column is the target variable and is of type `object`. If the name ends with `act1` or `ac1`, it belongs to one class (Class 1), and if it ends with `decoy1`, it belongs to another class (Class 0). Convert this to numerical values (0 and 1).\n",
    "\n",
    "2. **Handle Constant Features:** From the histograms and describe() output, we notice that certain features have a constant value (e.g., std = 0), indicating that they do not vary and are not informative for the model. We'll drop these features, using the `drop()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Fix the Name column by setting the value to 0 if the name contains \"decoy1\" and 1 if the name contains \"act1\" or \"ac1\"\n",
    "# Print the value counts of the Name column using value_counts() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Find the columns with only one unique value\n",
    "# Drop the columns with only one unique value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.2 Feature Selection**\n",
    "\n",
    "To identify the most relevant features for your machine learning model, you can start with a correlation matrix and then visualize the feature relationships.\n",
    "\n",
    "1. **Correlation Matrix**:  \n",
    "   A correlation matrix helps identify the relationships between features. Correlation values range from -1 to 1:\n",
    "\n",
    "   - A value close to **1** indicates a strong positive correlation.\n",
    "   - A value close to **-1** indicates a strong negative correlation.\n",
    "   - A value close to **0** indicates weak or no correlation.\n",
    "\n",
    "   Use `df.corr()` to calculate the correlation matrix and `sns.heatmap()` to visualize it. Remove highly correlated features to reduce multicollinearity.\n",
    "\n",
    "2. **Pairplot**:  \n",
    "   To visualize the relationships between these features further, you can create a pairplot using the `sns.pairplot()` function. This plot displays the pairwise relationships in a dataset, making it easier to identify patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Calculate the correlation matrix of the dataset using the corr() method\n",
    "# Plot the correlation matrix using a heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Plot a pairplot of the dataset using sns.pairplot\n",
    "# Set the hue to the Name column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now based on the correlation matrix and pairplot, you can decide which features to keep for the machine learning model. Drop the unnecessary features from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    # TODO: Add the columns to drop\n",
    "]\n",
    "# TODO: Drop the columns in the columns_to_drop list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.3 Standardizing the Data**\n",
    "\n",
    "Standardization is important to scale the features so that they have a mean of 0 and a standard deviation of 1. This ensures that each feature contributes equally to the model, especially for algorithms sensitive to feature scales.\n",
    "\n",
    "**Action**:\n",
    "\n",
    "1. Use `StandardScaler` from `sklearn.preprocessing` to standardize the features.\n",
    "2. Apply the scaler to all features, excluding the target variable.\n",
    "3. Replace the original features with the standardized values in the DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Instantiate the StandardScaler object\n",
    "# Fit and transform the data using the scaler\n",
    "# Create a DataFrame of the scaled data\n",
    "# Add the Name column back to the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.4 Separating the Target and Features**\n",
    "\n",
    "Before building the machine learning model, you need to separate the target variable from the feature variables.\n",
    "\n",
    "**Action**:\n",
    "\n",
    "1. Create a variable `X` containing all feature columns and another variable `y` containing the target column.\n",
    "2. Check the shape of `X` and `y` to ensure they are correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Separate the features and the target variable\n",
    "# Keep the features in a DataFrame called X\n",
    "# Keep the target variable in a Series called y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Model Building**\n",
    "\n",
    "Now that the data is preprocessed and ready, you can proceed with building a machine learning model.\n",
    "\n",
    "#### **6.1 Train-Test Split**\n",
    "\n",
    "Before training the model, split the data into training and testing sets. This allows you to train the model on one set of data and test its performance on unseen data.\n",
    "\n",
    "- Use `train_test_split` from `sklearn.model_selection` to split the data. The typical split ratio is 80% training and 20% testing.\n",
    "- Set `stratify=y` to ensure that the class distribution is similar in both training and testing sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6.2 Model Selection**\n",
    "\n",
    "For this task, you can choose any classification algorithm to build the model. Here are a few popular algorithms you can consider:\n",
    "\n",
    "**Traditional Classifiers:**\n",
    "\n",
    "- `LogisticRegression`\n",
    "- `KNeighborsClassifier`\n",
    "- `SVC` (Support Vector Classifier)\n",
    "- `DecisionTreeClassifier`\n",
    "- `RandomForestClassifier`\n",
    "- `GradientBoostingClassifier`\n",
    "- `AdaBoostClassifier`\n",
    "- `XGBClassifier` (if using `XGBoost`)\n",
    "\n",
    "**Deep Neural Network Classifier:**\n",
    "\n",
    "- `MLPClassifier` (Multi-layer Perceptron from `sklearn.neural_network`)\n",
    "\n",
    "Initialize the chosen model using appropriate parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Instantiate a Classifier object of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6.3 Model Training**\n",
    "\n",
    "Train the initialized model on the training data using the `fit()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Fit the classifier object on the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6.4 Predictions and Evaluation**\n",
    "\n",
    "After training the model, make predictions on the test data and evaluate its performance using various metrics.\n",
    "\n",
    "**1. Predictions:**\n",
    "\n",
    "Use the `predict()` function to predict the target values on the test set, and save them as `y_pred`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Predict the labels of the testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Confusion Matrix:**\n",
    "\n",
    "Wtrite a function to plot the confusion matrix to visualize the model's performance. Use `confusion_matrix` from `sklearn.metrics` and `heatmap` from `seaborn` to plot the matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    # TODO:\n",
    "    # Use the confusion_matrix function to calculate the confusion matrix\n",
    "    # Plot the confusion matrix using sns.heatmap\n",
    "    # Set the x-axis label to \"Predicted\" and the y-axis label to \"Actual\"\n",
    "    # Set the title to \"Confusion Matrix\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. ROC-AUC Curve:**\n",
    "\n",
    "Plot the ROC-AUC curve to visualize the trade-off between the True Positive Rate and False Positive Rate. Use `roc_curve` and `auc` functions from `sklearn.metrics` to plot the curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_pred):\n",
    "    # TODO:\n",
    "    # Use roc_curve from sklearn.metrics to get the fpr, tpr, thresholds\n",
    "    # Use auc from sklearn.metrics to get the auc\n",
    "    # Plot the fpr vs tpr\n",
    "    # Plot the line y=x in red as referrence for random classifier\n",
    "    # Add labels and title to the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Evaluate the Model:**\n",
    "\n",
    "Use the `classification_report` function from `sklearn.metrics` to print a summary of the model's performance, including precision, recall, F1-score, and accuracy. Plot the ROC-AUC curve and confusion matrix to visualize the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Print the classification report using classification_report from sklearn.metrics\n",
    "# Use plot_confusion_matrix to plot the confusion matrix\n",
    "# Use plot_roc_curve to plot the ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Improving Model Performance**\n",
    "\n",
    "In this section, we will focus on improving the model's performance by addressing the issues related to the classification of the active class, which has fewer data points. There are several techniques to handle imbalanced datasets:\n",
    "\n",
    "- **Find the Optimal Threshold:** Adjust the classification threshold to balance precision and recall.\n",
    "- **Resampling Techniques:** Oversample the minority class (SMOTE) or undersample the majority class to balance the class distribution.\n",
    "- **Data Augmentation:** Generate synthetic samples by adding noise to the existing data points.\n",
    "- **Balanced Bagging:** Use ensemble methods like BalancedRandomForestClassifier or EasyEnsemble to handle imbalanced datasets.\n",
    "\n",
    "#### **7.1 Find the Optimal Threshold**\n",
    "\n",
    "To find the optimal threshold, you can plot the Precision-Recall curve and identify the threshold that balances precision and recall. Use the `precision_recall_curve` function from `sklearn.metrics` to plot the curve.\n",
    "\n",
    "**Steps**:\n",
    "\n",
    "- Use `predict_proba` to get the probabilities of the positive class.\n",
    "- Call the `precision_recall_curve` function to get the precision, recall, and threshold values.\n",
    "- Calculate the F1-score using the precision and recall values.\n",
    "  $$F1 = 2 * \\frac{Precision * Recall}{Precision + Recall}$$\n",
    "- Find the optimal threshold where the f1-score is maximum.\n",
    "- Print the optimal threshold value.\n",
    "- Calculate the `y_pred` from the probabilities using the optimal threshold. i.e., if the probability is greater than the threshold, predict 1; otherwise, predict 0.\n",
    "- Evaluate the model using the confusion matrix, classification report, and ROC-AUC curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your code here to find the best threshold\n",
    "\n",
    "# TODO: Write your code here to predict the labels based on the best threshold\n",
    "\n",
    "# TODO: Write your code here to plot the confusion matrix, classification report, and ROC curve for the best threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7.2 Fix using Resampling Techniques**\n",
    "\n",
    "If the model performance is still not satisfactory, you can try using resampling techniques to balance the class distribution. Use sklearn's `resample` function to oversample the minority class or undersample the majority class.\n",
    "\n",
    "**Steps**:\n",
    "\n",
    "- Split the data 'X' and 'y' into training and testing sets using `train_test_split`.\n",
    "- Concatenate 'X_train' and 'y_train' to create a training dataset.\n",
    "- Find the indices of the minority and majority classes. Use boolean indexing on the target variable.\n",
    "- Use `resample` to oversample the minority class.\n",
    "- Concatenate the resampled minority class with the majority class.\n",
    "- Separate the target variable from the features.\n",
    "- Train the model on the resampled data and evaluate its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your code here to split the data into training and testing sets\n",
    "\n",
    "# Find the majority and minority classes\n",
    "train_majority = pd.concat([X_train, y_train], axis=1)[y_train == 0]\n",
    "train_minority = pd.concat([X_train, y_train], axis=1)[y_train == 1]\n",
    "\n",
    "# Upsample the minority class by resampling with replacement\n",
    "train_minority_upsampled = resample(\n",
    "    train_minority, replace=True, n_samples=len(train_majority), random_state=42\n",
    ")\n",
    "\n",
    "# Combine the majority class with the upsampled minority class and shuffle the data\n",
    "train_upsampled = pd.concat([train_majority, train_minority_upsampled])\n",
    "train_upsampled = train_upsampled.sample(frac=1, random_state=42)\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X_train = train_upsampled.drop(\"Name\", axis=1)\n",
    "y_train = train_upsampled[\"Name\"]\n",
    "\n",
    "\n",
    "# TODO: \n",
    "# Fit the classifier object on the new training data\n",
    "# Predict the labels of the testing data\n",
    "\n",
    "# TODO:\n",
    "# Print the classification report using classification_report from sklearn.metrics\n",
    "# Use plot_confusion_matrix to plot the confusion matrix\n",
    "# Use plot_roc_curve to plot the ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7.3 Fix using SMOTE resampling**\n",
    "\n",
    "Another popular technique to handle imbalanced datasets is Synthetic Minority Over-sampling Technique (SMOTE). It generates synthetic samples for the minority class by interpolating between existing samples.\n",
    "\n",
    "**Steps**:\n",
    "\n",
    "- Split the data 'X' and 'y' into training and testing sets using `train_test_split`.\n",
    "- Use `SMOTE` from `imblearn.over_sampling` to resample the data.\n",
    "- Split the data into training and testing sets.\n",
    "- Initialize the SMOTE model with appropriate parameters.\n",
    "- Fit the SMOTE model on the training data and resample it.\n",
    "- Train the model on the resampled data and evaluate its performance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split the data into training and testing sets\n",
    "\n",
    "# Instantiate the SMOTE object\n",
    "smote = SMOTE(sampling_strategy=\"minority\", random_state=42)\n",
    "\n",
    "# Use SMOTE to oversample the minority class\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Shuffle the data\n",
    "oversampled = pd.concat([X_train, y_train], axis=1)\n",
    "oversampled = oversampled.sample(frac=1, random_state=42)\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X_train = oversampled.drop(\"Name\", axis=1)\n",
    "y_train = oversampled[\"Name\"]\n",
    "\n",
    "# TODO:\n",
    "# Fit the classifier object on the new training data\n",
    "# Predict the labels of the testing data\n",
    "\n",
    "# TODO:\n",
    "# Print the classification report using classification_report from sklearn.metrics\n",
    "# Use plot_confusion_matrix to plot the confusion matrix\n",
    "# Use plot_roc_curve to plot the ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7.4 Balanced Bagging**\n",
    "\n",
    "Balanced Bagging is an ensemble method that combines multiple classifiers trained on balanced bootstrap samples. It helps improve the model's performance on imbalanced datasets. Use `BalancedBaggingClassifier` from `imblearn.ensemble` to train the model.\n",
    "\n",
    "**Steps**:\n",
    "\n",
    "- Split the data 'X' and 'y' into training and testing sets using `train_test_split`.\n",
    "- Initialize the `BalancedBaggingClassifier` with the base classifier (e.g., DecisionTreeClassifier, RandomForestClassifier).\n",
    "- Train the model on the training data.\n",
    "- Evaluate the model's performance using the confusion matrix, classification report, and ROC-AUC curve.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split the data into training and testing sets\n",
    "\n",
    "# TODO: Instantiate a BalancedBaggingClassifier object with estimator as your choosen classifier\n",
    "\n",
    "# TODO:\n",
    "# Fit the new classifier object on the training data\n",
    "# Predict the labels of the testing data\n",
    "\n",
    "# TODO:\n",
    "# Print the classification report using classification_report from sklearn.metrics\n",
    "# Use plot_confusion_matrix to plot the confusion matrix\n",
    "# Use plot_roc_curve to plot the ROC curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7.5 Augmenting Data**\n",
    "\n",
    "Data augmentation is another technique to handle imbalanced datasets by generating synthetic samples. You can add noise to the existing data points to create new samples.\n",
    "\n",
    "**Steps**:\n",
    "- Split the data 'X' and 'y' into training and testing sets using `train_test_split`.\n",
    "- Concatenate 'X_train' and 'y_train' to create a training dataset.\n",
    "- Find the indices of the minority and majority classes. Use boolean indexing on the target variable.\n",
    "- Use `resample` to oversample the minority class.\n",
    "- Use `np.random.normal` to generate noise with the same shape as the upsampled minority class.\n",
    "- Add the noise to the upsampled minority class to create augmented data.\n",
    "- Concatenate the augmented data with the majority class.\n",
    "- Separate the target variable from the features.\n",
    "- Train the model on the augmented data and evaluate its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split the data into training and testing sets\n",
    "\n",
    "# Find the majority and minority classes\n",
    "train_majority = pd.concat([X_train, y_train], axis=1)[y_train == 0]\n",
    "train_minority = pd.concat([X_train, y_train], axis=1)[y_train == 1]\n",
    "\n",
    "# Upsample the minority class by resampling with replacement\n",
    "train_minority_upsampled = resample(\n",
    "    train_minority, replace=True, n_samples=len(train_majority), random_state=42\n",
    ")\n",
    "\n",
    "# Add random noise to the upsampled data\n",
    "train_minority_upsampled.iloc[:, :-1] += np.random.normal(\n",
    "    0, 0.01, train_minority_upsampled.iloc[:, :-1].shape\n",
    ")\n",
    "\n",
    "# Combine the majority class with the upsampled minority class and shuffle the data\n",
    "train_upsampled = pd.concat([train_majority, train_minority_upsampled])\n",
    "train_upsampled = train_upsampled.sample(frac=1, random_state=42)\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X_train = train_upsampled.drop(\"Name\", axis=1)\n",
    "y_train = train_upsampled[\"Name\"]\n",
    "\n",
    "# TODO:\n",
    "# Fit the classifier object on the new training data\n",
    "# Predict the labels of the testing data\n",
    "\n",
    "# TODO:\n",
    "# Print the classification report using classification_report from sklearn.metrics\n",
    "# Use plot_confusion_matrix to plot the confusion matrix\n",
    "# Use plot_roc_curve to plot the ROC curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8. Evaluate performance on another dataset**\n",
    "\n",
    "- Load another protein dataset (e.g., `casp3.csv`) and preprocess it similarly to the previous dataset.\n",
    "- Use the trained model to make predictions on this new dataset.\n",
    "- Evaluate the model's performance using the confusion matrix, classification report, and ROC-AUC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Load another dataset\n",
    "# Reomve the columns you removed in the previous dataset\n",
    "# Use the scaler you used in the previous dataset to scale the new dataset\n",
    "# Separate the features and the target variable\n",
    "# Test the classifier you trained on the previous dataset on the new dataset\n",
    "# Evaluate the classifier using the classification report, confusion matrix, and ROC curve\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
